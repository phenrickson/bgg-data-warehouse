# Cloud Build configuration for BGG processor
steps:
  # Create Artifact Registry repository if it doesn't exist
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Check if repository exists, create if not
        gcloud artifacts repositories describe bgg-data-warehouse \
          --location=us-central1 \
          --format="value(name)" 2>/dev/null || \
        gcloud artifacts repositories create bgg-data-warehouse \
          --repository-format=docker \
          --location=us-central1 \
          --description="BGG Data Warehouse container images"

  # Build the processor image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'us-central1-docker.pkg.dev/$PROJECT_ID/bgg-data-warehouse/processor:${_ENVIRONMENT}', '.']

  # Build the dashboard image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'us-central1-docker.pkg.dev/$PROJECT_ID/bgg-data-warehouse/dashboard:${_ENVIRONMENT}', '-f', 'Dockerfile.dashboard', '.']

  # Push the processor image to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'us-central1-docker.pkg.dev/$PROJECT_ID/bgg-data-warehouse/processor:${_ENVIRONMENT}']

  # Push the dashboard image to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'us-central1-docker.pkg.dev/$PROJECT_ID/bgg-data-warehouse/dashboard:${_ENVIRONMENT}']

  # Deploy Fetch Responses Cloud Run Job (create or update)
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Try to update first, if it fails (job doesn't exist), create it
        gcloud run jobs update bgg-fetch-responses-${_ENVIRONMENT} \
          --image=us-central1-docker.pkg.dev/$PROJECT_ID/bgg-data-warehouse/processor:${_ENVIRONMENT} \
          --tasks=1 \
          --max-retries=3 \
          --task-timeout=1h \
          --memory=2Gi \
          --cpu=1 \
          --region=us-central1 \
          --service-account=bgg-data-warehouse@$PROJECT_ID.iam.gserviceaccount.com \
          --set-env-vars=ENVIRONMENT=${_ENVIRONMENT},PIPELINE_STAGE=fetch_responses \
        || gcloud run jobs create bgg-fetch-responses-${_ENVIRONMENT} \
          --image=us-central1-docker.pkg.dev/$PROJECT_ID/bgg-data-warehouse/processor:${_ENVIRONMENT} \
          --tasks=1 \
          --max-retries=3 \
          --task-timeout=1h \
          --memory=2Gi \
          --cpu=1 \
          --region=us-central1 \
          --service-account=bgg-data-warehouse@$PROJECT_ID.iam.gserviceaccount.com \
          --set-env-vars=ENVIRONMENT=${_ENVIRONMENT},PIPELINE_STAGE=fetch_responses

  # Deploy Process Responses Cloud Run Job (create or update)
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Try to update first, if it fails (job doesn't exist), create it
        gcloud run jobs update bgg-process-responses-${_ENVIRONMENT} \
          --image=us-central1-docker.pkg.dev/$PROJECT_ID/bgg-data-warehouse/processor:${_ENVIRONMENT} \
          --tasks=1 \
          --max-retries=3 \
          --task-timeout=1h \
          --memory=2Gi \
          --cpu=1 \
          --region=us-central1 \
          --service-account=bgg-data-warehouse@$PROJECT_ID.iam.gserviceaccount.com \
          --set-env-vars=ENVIRONMENT=${_ENVIRONMENT},PIPELINE_STAGE=process_responses \
        || gcloud run jobs create bgg-process-responses-${_ENVIRONMENT} \
          --image=us-central1-docker.pkg.dev/$PROJECT_ID/bgg-data-warehouse/processor:${_ENVIRONMENT} \
          --tasks=1 \
          --max-retries=3 \
          --task-timeout=1h \
          --memory=2Gi \
          --cpu=1 \
          --region=us-central1 \
          --service-account=bgg-data-warehouse@$PROJECT_ID.iam.gserviceaccount.com \
          --set-env-vars=ENVIRONMENT=${_ENVIRONMENT},PIPELINE_STAGE=process_responses

  # Deploy Refresh Games Cloud Run Job (create or update)
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Try to update first, if it fails (job doesn't exist), create it
        gcloud run jobs update bgg-refresh-games-${_ENVIRONMENT} \
          --image=us-central1-docker.pkg.dev/$PROJECT_ID/bgg-data-warehouse/processor:${_ENVIRONMENT} \
          --tasks=1 \
          --max-retries=3 \
          --task-timeout=1h \
          --memory=2Gi \
          --cpu=1 \
          --region=us-central1 \
          --service-account=bgg-data-warehouse@$PROJECT_ID.iam.gserviceaccount.com \
          --set-env-vars=ENVIRONMENT=${_ENVIRONMENT},PIPELINE_STAGE=refresh_games,MAX_GAMES=15000 \
        || gcloud run jobs create bgg-refresh-games-${_ENVIRONMENT} \
          --image=us-central1-docker.pkg.dev/$PROJECT_ID/bgg-data-warehouse/processor:${_ENVIRONMENT} \
          --tasks=1 \
          --max-retries=3 \
          --task-timeout=1h \
          --memory=2Gi \
          --cpu=1 \
          --region=us-central1 \
          --service-account=bgg-data-warehouse@$PROJECT_ID.iam.gserviceaccount.com \
          --set-env-vars=ENVIRONMENT=${_ENVIRONMENT},PIPELINE_STAGE=refresh_games,MAX_GAMES=15000

# Images to push to Artifact Registry
images:
  - 'us-central1-docker.pkg.dev/$PROJECT_ID/bgg-data-warehouse/processor:${_ENVIRONMENT}'
  - 'us-central1-docker.pkg.dev/$PROJECT_ID/bgg-data-warehouse/dashboard:${_ENVIRONMENT}'

# Timeout for the entire build
timeout: '1800s'  # 30 minutes
