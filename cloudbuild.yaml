# Cloud Build configuration for BGG processor
steps:
  # Build the processor image with environment tag
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-f', 'docker/Dockerfile.pipeline', '-t', 'gcr.io/$PROJECT_ID/bgg-processor:$_ENVIRONMENT', '.']

  # Push the image to Container Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/bgg-processor:$_ENVIRONMENT']

  # Deploy Fetch New Games Cloud Run Job - Create if not exists, otherwise update
  # This job fetches new game IDs and responses, then triggers async processing via Pub/Sub
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        if gcloud run jobs describe bgg-fetch-new-games-$_ENVIRONMENT --region=us-central1 2>/dev/null; then
          echo "Updating existing job: bgg-fetch-new-games-$_ENVIRONMENT"
          gcloud run jobs update bgg-fetch-new-games-$_ENVIRONMENT \
            --image=gcr.io/$PROJECT_ID/bgg-processor:$_ENVIRONMENT \
            --args=src.pipeline.fetch_new_games \
            --tasks=1 \
            --max-retries=3 \
            --task-timeout=3h \
            --memory=4Gi \
            --cpu=2 \
            --region=us-central1 \
            --service-account=bgg-data-warehouse@$PROJECT_ID.iam.gserviceaccount.com \
            --set-env-vars=ENVIRONMENT=$_ENVIRONMENT,BGG_API_TOKEN=$_BGG_API_TOKEN
        else
          echo "Creating new job: bgg-fetch-new-games-$_ENVIRONMENT"
          gcloud run jobs create bgg-fetch-new-games-$_ENVIRONMENT \
            --image=gcr.io/$PROJECT_ID/bgg-processor:$_ENVIRONMENT \
            --args=src.pipeline.fetch_new_games \
            --tasks=1 \
            --max-retries=3 \
            --task-timeout=3h \
            --memory=4Gi \
            --cpu=2 \
            --region=us-central1 \
            --service-account=bgg-data-warehouse@$PROJECT_ID.iam.gserviceaccount.com \
            --set-env-vars=ENVIRONMENT=$_ENVIRONMENT,BGG_API_TOKEN=$_BGG_API_TOKEN
        fi

  # Deploy Refresh Old Games Cloud Run Job - Create if not exists, otherwise update
  # This job refreshes stale game data, then triggers async processing via Pub/Sub
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        if gcloud run jobs describe bgg-refresh-old-games-$_ENVIRONMENT --region=us-central1 2>/dev/null; then
          echo "Updating existing job: bgg-refresh-old-games-$_ENVIRONMENT"
          gcloud run jobs update bgg-refresh-old-games-$_ENVIRONMENT \
            --image=gcr.io/$PROJECT_ID/bgg-processor:$_ENVIRONMENT \
            --args=src.pipeline.refresh_old_games \
            --tasks=1 \
            --max-retries=3 \
            --task-timeout=3h \
            --memory=4Gi \
            --cpu=2 \
            --region=us-central1 \
            --service-account=bgg-data-warehouse@$PROJECT_ID.iam.gserviceaccount.com \
            --set-env-vars=ENVIRONMENT=$_ENVIRONMENT,BGG_API_TOKEN=$_BGG_API_TOKEN
        else
          echo "Creating new job: bgg-refresh-old-games-$_ENVIRONMENT"
          gcloud run jobs create bgg-refresh-old-games-$_ENVIRONMENT \
            --image=gcr.io/$PROJECT_ID/bgg-processor:$_ENVIRONMENT \
            --args=src.pipeline.refresh_old_games \
            --tasks=1 \
            --max-retries=3 \
            --task-timeout=3h \
            --memory=4Gi \
            --cpu=2 \
            --region=us-central1 \
            --service-account=bgg-data-warehouse@$PROJECT_ID.iam.gserviceaccount.com \
            --set-env-vars=ENVIRONMENT=$_ENVIRONMENT,BGG_API_TOKEN=$_BGG_API_TOKEN
        fi

  # Create Pub/Sub topic if it doesn't exist
  # This topic is used to trigger the response processing Cloud Function
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        if gcloud pubsub topics describe process-responses 2>/dev/null; then
          echo "Pub/Sub topic 'process-responses' already exists"
        else
          echo "Creating Pub/Sub topic 'process-responses'"
          gcloud pubsub topics create process-responses
        fi

  # Deploy Response Processing Cloud Function
  # This function is triggered by Pub/Sub when fetch scripts complete
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Deploying Cloud Function: process-responses-$_ENVIRONMENT"
        gcloud functions deploy process-responses-$_ENVIRONMENT \
          --gen2 \
          --runtime=python311 \
          --region=us-central1 \
          --source=./src/cloud_functions/process_responses \
          --entry-point=process_responses \
          --trigger-topic=process-responses \
          --timeout=540s \
          --memory=512MB \
          --service-account=bgg-data-warehouse@$PROJECT_ID.iam.gserviceaccount.com \
          --set-env-vars=ENVIRONMENT=$_ENVIRONMENT

# Images to push to Container Registry
images:
  - 'gcr.io/$PROJECT_ID/bgg-processor:$_ENVIRONMENT'

# Timeout for the entire build
timeout: '1800s'  # 30 minutes
